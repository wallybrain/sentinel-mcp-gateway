---
phase: 07-health-reliability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Cargo.toml
  - src/lib.rs
  - src/health/mod.rs
  - src/health/server.rs
  - src/health/checker.rs
  - src/health/circuit_breaker.rs
  - src/config/types.rs
autonomous: true
requirements: [HEALTH-01, HEALTH-02, HEALTH-03, HEALTH-04]

must_haves:
  truths:
    - "GET /health returns 200 with JSON body when the gateway process is running"
    - "GET /ready returns 200 when at least one backend is healthy, 503 when none are healthy"
    - "Health checker periodically pings backends and updates shared health state"
    - "Circuit breaker opens after N consecutive failures and transitions through closed/open/half-open states"
  artifacts:
    - path: "src/health/mod.rs"
      provides: "Module declaration for server, checker, circuit_breaker"
    - path: "src/health/server.rs"
      provides: "Axum HTTP server with /health and /ready routes"
      exports: ["run_health_server", "BackendHealthMap", "BackendHealth"]
    - path: "src/health/checker.rs"
      provides: "Background health check loop"
      exports: ["health_checker"]
    - path: "src/health/circuit_breaker.rs"
      provides: "Per-backend circuit breaker state machine"
      exports: ["CircuitBreaker", "CircuitState"]
  key_links:
    - from: "src/health/server.rs"
      to: "src/health/checker.rs"
      via: "Shared BackendHealthMap (Arc<RwLock<HashMap>>)"
      pattern: "BackendHealthMap"
    - from: "src/health/checker.rs"
      to: "src/backend/http.rs"
      via: "Uses HttpBackend.send() to ping backends"
      pattern: "backend\\.send"
    - from: "src/health/circuit_breaker.rs"
      to: "src/gateway.rs"
      via: "CircuitBreaker.allow_request() called before backend dispatch (wired in plan 02)"
      pattern: "allow_request"
---

<objective>
Build the health module: axum HTTP server for /health and /ready probes, background health checker that pings HTTP backends, circuit breaker state machine, and shared health state types.

Purpose: The gateway currently has no way for Docker/monitoring to check if it is alive or if backends are reachable. This plan creates all the health infrastructure as self-contained modules with unit tests, ready to be wired into main.rs and gateway.rs in plan 02.

Output: Compiling health module with unit tests for all three sub-modules.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-health-reliability/07-RESEARCH.md
@src/main.rs
@src/gateway.rs
@src/config/types.rs
@src/backend/mod.rs
@src/lib.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and create health module with server, checker, and circuit breaker</name>
  <files>
    Cargo.toml
    src/lib.rs
    src/config/types.rs
    src/health/mod.rs
    src/health/server.rs
    src/health/checker.rs
    src/health/circuit_breaker.rs
  </files>
  <action>
1. Add dependencies to Cargo.toml:
   - `axum = "0.8"` (HTTP server for health endpoints)
   - `tokio-util = { version = "0.7", features = ["rt"] }` (CancellationToken for shutdown coordination)

2. Add `health_listen` field to `GatewayConfig` in src/config/types.rs:
   - `#[serde(default = "default_health_listen")] pub health_listen: String`
   - Default: `"127.0.0.1:9201"`
   - Add `default_health_listen()` function
   - Update the `Default` impl for GatewayConfig to include this field

3. Add `circuit_breaker_threshold` and `circuit_breaker_recovery_secs` fields to `BackendConfig`:
   - `#[serde(default = "default_cb_threshold")] pub circuit_breaker_threshold: u32` (default: 5)
   - `#[serde(default = "default_cb_recovery")] pub circuit_breaker_recovery_secs: u64` (default: 30)
   - Add the default functions

4. Add `pub mod health;` to src/lib.rs

5. Create src/health/mod.rs:
   ```rust
   pub mod checker;
   pub mod circuit_breaker;
   pub mod server;
   ```

6. Create src/health/circuit_breaker.rs:
   - `CircuitState` enum: Closed, Open, HalfOpen
   - `CircuitBreaker` struct with:
     - `state: AtomicU8` (0=Closed, 1=Open, 2=HalfOpen)
     - `failure_count: AtomicU32`
     - `failure_threshold: u32`
     - `recovery_timeout: Duration`
     - `last_failure: Mutex<Option<Instant>>`
   - `CircuitBreaker::new(threshold: u32, recovery_timeout: Duration) -> Self`
   - `CircuitBreaker::allow_request(&self) -> bool`:
     - Closed: always true
     - Open: check if recovery_timeout elapsed since last_failure. If yes, transition to HalfOpen and return true. If no, return false.
     - HalfOpen: return true (allow one probe)
   - `CircuitBreaker::record_success(&self)`: reset failure_count to 0, set state to Closed
   - `CircuitBreaker::record_failure(&self)`: increment failure_count, update last_failure. If count >= threshold, set state to Open.
   - `CircuitBreaker::state(&self) -> CircuitState`: return current state for readability
   - Use `Ordering::SeqCst` for state transitions (correctness over micro-optimization)
   - Unit tests: test closed allows, open blocks, half-open transition after timeout, success resets to closed, threshold behavior

7. Create src/health/server.rs:
   - Define `BackendHealth` struct: `{ pub healthy: bool, pub last_check: Instant, pub consecutive_failures: u32 }`
   - Define `pub type BackendHealthMap = Arc<RwLock<HashMap<String, BackendHealth>>>;`
   - `async fn liveness() -> Json<Value>`: returns `{"status": "ok"}`
   - `async fn readiness(State(health_map): State<BackendHealthMap>) -> (StatusCode, Json<Value>)`:
     - Read lock on health_map
     - If map is empty, return 503 `{"status": "not_ready", "reason": "no backends registered"}`
     - If any backend has `healthy: true`, return 200 `{"status": "ready"}`
     - Otherwise 503 `{"status": "not_ready"}`
   - `pub async fn run_health_server(addr: &str, health_map: BackendHealthMap, cancel: CancellationToken)`:
     - Build axum Router with /health and /ready routes
     - Bind TcpListener to addr
     - Use `axum::serve(listener, app).with_graceful_shutdown(cancel.cancelled_owned())`
   - Unit tests: test liveness always returns 200, readiness returns 503 on empty map, 200 when one backend healthy, 503 when all unhealthy

8. Create src/health/checker.rs:
   - `pub async fn health_checker(backends: Vec<(String, HttpBackend)>, health_map: BackendHealthMap, cancel: CancellationToken, interval_secs: u64)`:
     - Create `tokio::time::interval(Duration::from_secs(interval_secs))`
     - Loop with `tokio::select!`:
       - On tick: for each backend, send an MCP `ping` request via `backend.send()`. Update health_map entry (healthy/unhealthy, last_check, consecutive_failures).
       - On cancel: log and break
     - The ping request is `{"jsonrpc":"2.0","id":1,"method":"ping"}` -- standard MCP ping
     - On success: set healthy=true, reset consecutive_failures to 0
     - On failure: increment consecutive_failures, set healthy=false
   - No unit tests needed for checker (it requires live backends; integration tested in plan 02)
  </action>
  <verify>
    `cargo build --release 2>&1 | tail -5` compiles with no errors. `cargo test --lib health 2>&1` runs circuit breaker and server unit tests and all pass.
  </verify>
  <done>
    Health module compiles. Circuit breaker unit tests prove state transitions (closed->open->half-open->closed). Server unit tests prove /health returns 200 and /ready returns correct status codes based on backend health state.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add CIRCUIT_OPEN_ERROR constant and integration test for circuit breaker logic</name>
  <files>
    src/protocol/jsonrpc.rs
    tests/circuit_breaker_test.rs
  </files>
  <action>
1. In src/protocol/jsonrpc.rs, add a new error constant:
   - `pub const CIRCUIT_OPEN_ERROR: i32 = -32007;`
   - This follows the project pattern: -32001 (auth), -32002 (not-init), -32003 (authz), -32005 (kill switch), -32006 (rate limit), -32007 (circuit open)

2. Create tests/circuit_breaker_test.rs as an integration test:
   - Test that a new CircuitBreaker starts in Closed state and allows requests
   - Test that after `failure_threshold` consecutive failures, state transitions to Open and `allow_request()` returns false
   - Test that after `recovery_timeout` elapses in Open state, it transitions to HalfOpen and allows one probe
   - Test that `record_success()` in HalfOpen transitions back to Closed
   - Test that `record_failure()` in HalfOpen transitions back to Open immediately (threshold effectively 1 in half-open)
   - Use `std::thread::sleep` for timeout tests (or small durations like 10ms for fast tests)
  </action>
  <verify>
    `cargo test --test circuit_breaker_test 2>&1` runs all integration tests and passes. `cargo build --release 2>&1 | tail -3` still compiles clean.
  </verify>
  <done>
    CIRCUIT_OPEN_ERROR (-32007) constant exists. Integration tests prove full circuit breaker lifecycle: closed -> open (after threshold failures) -> half-open (after recovery timeout) -> closed (on success) and half-open -> open (on failure).
  </done>
</task>

</tasks>

<verification>
- `cargo build --release` compiles with no errors or warnings
- `cargo test` runs all existing tests plus new health module tests, all passing
- `src/health/` directory exists with mod.rs, server.rs, checker.rs, circuit_breaker.rs
- CIRCUIT_OPEN_ERROR constant is -32007
- GatewayConfig has health_listen field defaulting to 127.0.0.1:9201
- BackendConfig has circuit_breaker_threshold and circuit_breaker_recovery_secs fields
</verification>

<success_criteria>
- Health module compiles and all unit/integration tests pass
- Circuit breaker implements correct 3-state machine (closed/open/half-open)
- Health server serves /health (200) and /ready (200 or 503 based on backend state)
- Health checker pings backends and updates shared health map
- No changes to main.rs or gateway.rs (those are wired in plan 02)
</success_criteria>

<output>
After completion, create `.planning/phases/07-health-reliability/07-01-SUMMARY.md`
</output>
