---
phase: 07-health-reliability
plan: 02
type: execute
wave: 2
depends_on: [07-01]
files_modified:
  - src/main.rs
  - src/gateway.rs
autonomous: true
requirements: [HEALTH-01, HEALTH-02, HEALTH-03, HEALTH-04, HEALTH-05]

must_haves:
  truths:
    - "Health HTTP server starts on configured port alongside stdio transport"
    - "Health checker runs in background and updates backend health state"
    - "Circuit breaker blocks requests to backends that have failed N consecutive times"
    - "SIGTERM triggers ordered shutdown: cancel dispatch -> drop audit_tx -> drain audit writer -> exit"
    - "Dispatch loop exits cleanly on CancellationToken cancel"
  artifacts:
    - path: "src/main.rs"
      provides: "Wires health server, health checker, circuit breakers, CancellationToken, and signal handler into startup sequence"
    - path: "src/gateway.rs"
      provides: "Dispatch loop with circuit breaker checks before backend calls and CancellationToken-aware select"
  key_links:
    - from: "src/main.rs"
      to: "src/health/server.rs"
      via: "Spawns run_health_server with health_map and cancel token"
      pattern: "run_health_server"
    - from: "src/main.rs"
      to: "src/health/checker.rs"
      via: "Spawns health_checker with backends and health_map"
      pattern: "health_checker"
    - from: "src/gateway.rs"
      to: "src/health/circuit_breaker.rs"
      via: "Checks allow_request() before backend.send(), records success/failure after"
      pattern: "allow_request|record_success|record_failure"
    - from: "src/main.rs"
      to: "tokio::signal"
      via: "Signal handler cancels CancellationToken on SIGTERM/SIGINT"
      pattern: "SignalKind::terminate"
---

<objective>
Wire the health module into main.rs and gateway.rs: spawn health HTTP server and background checker on startup, integrate circuit breaker into the dispatch loop, and add graceful shutdown via CancellationToken + signal handler.

Purpose: The health module from plan 01 is self-contained. This plan connects it to the running gateway so /health and /ready are live, backends are monitored, circuit breakers protect against failing backends, and SIGTERM triggers ordered shutdown.

Output: Fully wired health and reliability features with integration tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-health-reliability/07-RESEARCH.md
@.planning/phases/07-health-reliability/07-01-SUMMARY.md
@src/main.rs
@src/gateway.rs
@src/health/mod.rs
@src/health/server.rs
@src/health/checker.rs
@src/health/circuit_breaker.rs
@src/audit/writer.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire health server, health checker, circuit breakers, and graceful shutdown into main.rs</name>
  <files>src/main.rs</files>
  <action>
1. Add imports for health module types and tokio-util CancellationToken:
   - `use sentinel_gateway::health::server::{run_health_server, BackendHealthMap};`
   - `use sentinel_gateway::health::checker::health_checker;`
   - `use sentinel_gateway::health::circuit_breaker::CircuitBreaker;`
   - `use tokio_util::sync::CancellationToken;`
   - `use tokio::signal::unix::{signal, SignalKind};`
   - `use std::time::Duration;`

2. After backend discovery, create shared health state:
   - `let health_map: BackendHealthMap = Arc::new(RwLock::new(HashMap::new()));`
   - Initialize each discovered backend in the map as healthy (optimistic start)

3. Create per-backend circuit breakers:
   - `let circuit_breakers: HashMap<String, CircuitBreaker> = backends_map.keys().map(|name| { ... }).collect();`
   - Use `backend_config.circuit_breaker_threshold` and `backend_config.circuit_breaker_recovery_secs` from each backend's config
   - Look up the matching BackendConfig by name for each backend

4. Create CancellationToken:
   - `let cancel = CancellationToken::new();`

5. Spawn signal handler task:
   ```rust
   let cancel_signal = cancel.clone();
   tokio::spawn(async move {
       let mut sigterm = signal(SignalKind::terminate()).expect("SIGTERM handler");
       let mut sigint = signal(SignalKind::interrupt()).expect("SIGINT handler");
       tokio::select! {
           _ = sigterm.recv() => tracing::info!("Received SIGTERM"),
           _ = sigint.recv() => tracing::info!("Received SIGINT"),
       }
       cancel_signal.cancel();
   });
   ```

6. Spawn health HTTP server:
   - `tokio::spawn(run_health_server(&config.gateway.health_listen, health_map.clone(), cancel.clone()));`

7. Spawn health checker:
   - Build a `Vec<(String, HttpBackend)>` from backends_map for the checker (clone backends)
   - Use the per-backend `health_interval_secs` -- for simplicity use the minimum interval across all backends, or use a fixed 30s default
   - `tokio::spawn(health_checker(backends_list, health_map.clone(), cancel.clone(), 30));`

8. Pass `cancel.clone()` and `&circuit_breakers` to `run_dispatch()` -- update the function signature (see Task 2)

9. After `run_dispatch` returns, implement ordered shutdown:
   ```rust
   // Ensure cancel is triggered (in case dispatch ended due to stdin close, not signal)
   cancel.cancel();

   // Drop audit_tx to signal the writer to drain
   drop(audit_tx);

   // Wait for audit writer to finish draining
   // (Store the JoinHandle from tokio::spawn of audit_writer, await it here)
   if let Some(handle) = audit_handle {
       let _ = handle.await;
   }

   tracing::info!("Shutdown complete");
   ```
   - This means the audit writer spawn must capture the JoinHandle: `let audit_handle = Some(tokio::spawn(audit::writer::audit_writer(pool, arx)));`
   - Store `audit_handle: Option<tokio::task::JoinHandle<()>>` alongside `audit_tx`

10. The `HttpBackend` needs to be cloneable for the health checker. Check if it already implements Clone (it wraps `reqwest::Client` which is Clone). If not, derive Clone on HttpBackend.
  </action>
  <verify>
    `cargo build --release 2>&1 | tail -5` compiles with no errors.
  </verify>
  <done>
    main.rs spawns health HTTP server on configured port, spawns background health checker, creates circuit breakers per backend, handles SIGTERM/SIGINT for graceful shutdown with ordered drain sequence (cancel -> drop audit_tx -> await audit writer).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add circuit breaker and CancellationToken to dispatch loop with integration tests</name>
  <files>
    src/gateway.rs
    tests/health_integration_test.rs
  </files>
  <action>
1. Update `run_dispatch` signature to accept circuit breakers and cancel token:
   - Add `circuit_breakers: &HashMap<String, CircuitBreaker>` parameter
   - Add `cancel: CancellationToken` parameter

2. Change the dispatch loop from `while let Some(line) = rx.recv().await` to use `tokio::select!`:
   ```rust
   loop {
       let line = tokio::select! {
           line = rx.recv() => match line {
               Some(l) => l,
               None => break, // stdin closed
           },
           _ = cancel.cancelled() => {
               tracing::info!("Dispatch loop cancelled by shutdown signal");
               break;
           }
       };
       // ... existing message handling ...
   }
   ```

3. In the `tools/call` handler, after rate limit check and RBAC check, before calling `handle_tools_call`, add circuit breaker check:
   ```rust
   // Circuit breaker check (after kill switch, rate limit, RBAC)
   if let Some(backend_name) = catalog.route(name) {
       if let Some(cb) = circuit_breakers.get(backend_name) {
           if !cb.allow_request() {
               let resp = JsonRpcResponse::error(
                   id.clone(),
                   CIRCUIT_OPEN_ERROR,
                   format!("Backend circuit open: {backend_name}"),
               );
               send_response(&tx, &resp).await;
               // Audit entry with status "circuit_open"
               if let Some(ref atx) = audit_tx {
                   let entry = AuditEntry { ... status: "circuit_open" ... latency_ms: 0 };
                   let _ = atx.try_send(entry);
               }
               continue;
           }
       }
   }
   ```

4. In `handle_tools_call`, accept circuit breakers and record success/failure:
   - Add `circuit_breakers: &HashMap<String, CircuitBreaker>` parameter
   - After `backend.send()` returns Ok: `circuit_breakers.get(&backend_name).map(|cb| cb.record_success());`
   - After `backend.send()` returns Err: `circuit_breakers.get(&backend_name).map(|cb| cb.record_failure());`

5. Import CIRCUIT_OPEN_ERROR in gateway.rs:
   - Add to the existing import from `crate::protocol::jsonrpc`

6. Update ALL existing tests that call `run_dispatch` to pass the new parameters:
   - `circuit_breakers: &HashMap::new()` (empty -- no circuit breakers in existing tests)
   - `cancel: CancellationToken::new()` (never cancelled in existing tests)
   - Check `tests/` directory for all integration test files that call run_dispatch and update them

7. Create tests/health_integration_test.rs with these tests:
   - **test_circuit_breaker_blocks_after_failures**: Create a circuit breaker with threshold=2. Call record_failure() twice. Verify allow_request() returns false. Verify that a tools/call through dispatch returns CIRCUIT_OPEN_ERROR (-32007).
   - **test_dispatch_exits_on_cancel**: Create a CancellationToken, start dispatch, cancel the token, verify dispatch returns Ok without hanging.
   - **test_health_endpoint_liveness**: Start health server on a random port, send GET /health, verify 200 response with `{"status":"ok"}`.
   - **test_health_endpoint_readiness_no_backends**: Start health server with empty health map, send GET /ready, verify 503.
   - **test_health_endpoint_readiness_with_healthy_backend**: Start health server, insert a healthy backend into the map, send GET /ready, verify 200.
  </action>
  <verify>
    `cargo test 2>&1 | tail -20` runs ALL tests (existing + new) and all pass. `cargo build --release 2>&1 | tail -5` compiles clean.
  </verify>
  <done>
    Dispatch loop checks circuit breaker before backend calls (enforcement order: kill switch -> rate limit -> RBAC -> circuit breaker -> backend call). Dispatch loop exits cleanly on CancellationToken cancel. Circuit breaker records success/failure after backend calls. All existing tests pass with updated signatures. New integration tests verify circuit breaker blocking, dispatch cancellation, and health endpoint behavior.
  </done>
</task>

</tasks>

<verification>
- `cargo build --release` compiles with zero errors
- `cargo test` passes all tests (existing + new health/circuit breaker tests)
- `GET /health` returns 200 (tested in integration test)
- `GET /ready` returns 200 with healthy backends, 503 with none (tested in integration test)
- Circuit breaker blocks requests after threshold failures (tested)
- Dispatch loop exits on CancellationToken cancel (tested)
- SIGTERM triggers ordered shutdown (manual verification: run binary, send SIGTERM, check logs for "Shutdown complete")
- Enforcement order preserved: kill switch -> rate limit -> RBAC -> circuit breaker -> backend call
</verification>

<success_criteria>
- Health HTTP server starts on port 9201 (configurable via health_listen)
- /health returns 200 always, /ready returns 200/503 based on backend health
- Background health checker pings backends periodically
- Circuit breaker opens after N failures, recovers via half-open probe
- SIGTERM/SIGINT triggers graceful shutdown with audit log drain
- All 5 HEALTH requirements (HEALTH-01 through HEALTH-05) are satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/07-health-reliability/07-02-SUMMARY.md`
</output>
